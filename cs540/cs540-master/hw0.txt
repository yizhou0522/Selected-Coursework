Yizhou Liu
liu773@wisc.edu
2020Fall CS540
9/4/2020




With the rapid development of science and technology, the advent of Artificial Intelligence (AI) has tremendously changed our lives. From self-driving cars to AlphaGo, from Google's real-time translation to Youtube’s algorithms, it is not uncommon to see the unparalleled advantages brought by AI. As a result, the authors of  “Stanford One Hundred Year Study on Artificial Intelligence 2016 Report” optimistically assumed that AI has “no cause for concern that AI is an imminent threat to humankind” (Stone et al., 2016, p4). However, while endorsing the idea that AI is generally safe and controllable, I believe that the potential caveat of AI should also receive more attention for the following two reasons.


To begin with, self-driving cars, a major application of AI technology, though considered to be technically safe without the need for human control, in fact, have caused several fatal accidents in recent years. For example, on March 18, 2018, a Uber self-driving car killed a pedestrian called Elaine Herzberg when she was stepping into the road, pulling her bicycle along the crosswalk. Uber quickly reacted by suspending the self-driving operations and began to investigate the causes of the accident (Schmelzer, 2019, forbes.com). It is worth noting that the car simply did not recognize the pedestrian, in parts due to the block of her bicycle. Consequently, it is well-needed to examine Computer Vision (CV) technology because self-driving cars mainly rely on this technique to discern obstacles or people. Like Jeremy Cohen, an AI Self-Driving Car engineer, pointed out, conventional Computer Vision on lane lines detection was ineffective, with rather slow reaction time (Cohen, 2019, researchgate.net). This may partly explain why Uber autonomous vehicles could not detect the pedestrian in a very short period and thus, the tragedy happened. As a result, despite the fact that self-driving cars do sometimes outperform human drivers, we still need to meticulously examine the potential drawbacks of the software and algorithms inside the cars and keep looking for better ones to not only to avoid the risks or accidents but to further increase the efficiency and reliability of the self-driving vehicles. 


Furthermore, due to the fact that AI is exclusively dependent on the algorithms and software, there are certain risks that hackers might attack the AI system and make use of the facilities illegally. According to a recent report from Cambridge University, there has seen increased risks for the potential misuse of AI by rogue states, criminals, as well as some lone-wolf attackers (Auchard, 2018, reuters.com). Then, these hackers could exploit the AI technology, doing illegal activities based on their self-interests. For example, spreading disinformation and deepfakes before the 2020 Presidential Election would be a potential misuse of AI technology (Choudhury, 2019, sciencedaily.com). If the hackers successfully crackdown the software, it will definitely affect the results of the election and bring great economic damages. Therefore, it is fair to say that increasing the security of AI technology is a must before the formal AI products are put to use in the market. 


In conclusion, as the aforementioned reasons illustrate, while AI does bring unprecedented benefits to human beings, we should not be overconfident and self-flattery for the safety concerns induced by AI; instead, only by continuing exploring and studying the further AI knowledge can we employ the AI as well as other advanced technologies securely and wisely.